{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Chap5-1_basics_of_convolutional_neural_network.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"7Uws2LHjAeIj","colab_type":"text"},"source":["# Basics of convolutional neural network  \n","\n","<strong>Abstract</strong>  \n","In this notebook, a convolutional neural network will be build using [Keras](https://keras.io). A basic usage will be described.\n","- Number of parameters.\n","- Sizes of inputs and outputs.\n","- [Convolution](https://keras.io/layers/convolutional/)\n","- [Max pooling](https://keras.io/layers/pooling/)\n","- Padding\n","\n","<strong>Reference</strong>  \n","See pages 120-129 of \"<strong>Deep Learning with Python</strong>\" by Francois Chollet (2018). \n","\n","<strong>Summary</strong>  \n","- Convolution layers learn local patters in contrast to dense layers that learn global patters (page 122, 123, see also Fig. 5.2).  \n","- The patterns that the convolutional neural networks learn are translation invariant (page 123). \n","- The convolution is typycally done with the convolution window is 3 x 3 or 5 x 5 (page 124) and no stride (page 128).\n","- The max-pooling operation is used (page 127) to downsample the feature map, which results in reducing the number of feature-map coefficients to process (page 128). This operation is done with 2 x 2 windows with stride 2 in order to downsample the feature maps by a factor of 2 (page 127-128). \n","- Even though there are other ways to achieve downsampling, max pooling tends to work better (page 129)."]},{"cell_type":"markdown","metadata":{"id":"WNXHpadcAiu6","colab_type":"text"},"source":["### Number of parameters"]},{"cell_type":"markdown","metadata":{"id":"T52dagoFdt5J","colab_type":"text"},"source":["<strong>model.add(layers.Conv2D(filters=32,kernel_size=(3,3), strides= 1, activation='relu', input_shape=(28,28,1)))</strong>   \n","- filters=32: The number of output filters in the convolution. In other words, it is the depth of the output feature map. This layer computes 32 filters over its input. \n","- kernel_size=(3,3): Size of a filter (i.e., the height and width of the 2D convolution window). This is typically 3 x 3 or 5 x 5. \n","- strides= 1: Strides of the convolution.\n","input_shape=(28,28,1): Height, width, and depth.\n","- More information: [keras documentation](https://keras.io/layers/convolutional/)    \n","         \n","<strong>model.add(layers.MaxPooling2D(pool_size=(2,2),strides=2))</strong>  \n","- pool_size=(2,2): Size of the max pooling windows\n","- strides=2: Factor by which to downscale. \n","- More information: [keras documentation](https://keras.io/layers/pooling/)"]},{"cell_type":"code","metadata":{"id":"cvSn1Ms8bI1O","colab_type":"code","outputId":"73d674ce-23bd-4bd7-b3d9-496e48b196b1","executionInfo":{"status":"ok","timestamp":1577177539619,"user_tz":-60,"elapsed":421,"user":{"displayName":"Kotaro Sonoda","photoUrl":"","userId":"14975548384331586092"}},"colab":{"base_uri":"https://localhost:8080/","height":425}},"source":["from keras import layers\n","from keras import models\n","\n","model = models.Sequential()\n","model.add(layers.Conv2D(filters=32,kernel_size=(3,3), strides= 1, activation='relu', input_shape=(28,28,1)))\n","model.add(layers.MaxPooling2D(pool_size=(2,2),strides=2))\n","model.add(layers.Conv2D(64,(3,3), activation='relu'))\n","model.add(layers.MaxPooling2D((2,2)))\n","model.add(layers.Conv2D(64,(3,3), activation='relu'))\n","model.add(layers.Flatten())\n","model.add(layers.Dense(64, activation = 'relu' ))\n","model.add(layers.Dense(10,activation='softmax'))\n","\n","model.summary()"],"execution_count":54,"outputs":[{"output_type":"stream","text":["Model: \"sequential_29\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_83 (Conv2D)           (None, 26, 26, 32)        320       \n","_________________________________________________________________\n","max_pooling2d_56 (MaxPooling (None, 13, 13, 32)        0         \n","_________________________________________________________________\n","conv2d_84 (Conv2D)           (None, 11, 11, 64)        18496     \n","_________________________________________________________________\n","max_pooling2d_57 (MaxPooling (None, 5, 5, 64)          0         \n","_________________________________________________________________\n","conv2d_85 (Conv2D)           (None, 3, 3, 64)          36928     \n","_________________________________________________________________\n","flatten_27 (Flatten)         (None, 576)               0         \n","_________________________________________________________________\n","dense_53 (Dense)             (None, 64)                36928     \n","_________________________________________________________________\n","dense_54 (Dense)             (None, 10)                650       \n","=================================================================\n","Total params: 93,322\n","Trainable params: 93,322\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IE6TaiRY6bvN","colab_type":"text"},"source":["<strong>model.summary()</strong> shows the structure of a neural network. The number of parameters (Param #) is shown in the table above and calculated in the next cell. Note that there are not parameters in the max pooling layers."]},{"cell_type":"code","metadata":{"id":"09NLUFbw3sAK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"1d9ec519-fcbd-4fe1-9b15-0632a9e5a99c","executionInfo":{"status":"ok","timestamp":1577175930273,"user_tz":-60,"elapsed":753,"user":{"displayName":"Kotaro Sonoda","photoUrl":"","userId":"14975548384331586092"}}},"source":["print(\"Number of parameters\")\n","print(\"conv2d (1):\", 3*3*1*32+32) # (filter width) x (filter height) x (input image channel) + (bias)\n","print(\"conv2d (2):\", 3*3*32*64+64) # (filter width) x (filter height) x (input channel size) x (output channel size) + (bias) \n","print(\"conv2d (3):\", 3*3*64*64+64) # (filter width) x (filter height) x (input channel size) x (output channel size) + (bias) \n","print(\"dense (1):\", 576*64+64) # (input channel size) x (output channel size) + (bias = output channel size)\n","print(\"dense (2):\", 64 * 10 +10) # # (input channel size) x (output channel size) + (bias = output channel size)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Number of parameters\n","conv2d (1): 320\n","conv2d (2): 18496\n","conv2d (3): 36928\n","dense (1): 36928\n","dense (2): 650\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BylJznhV7bFb","colab_type":"text"},"source":["Let us calculate the number of parameters for another neural network in order to get familiarized with parameters."]},{"cell_type":"code","metadata":{"id":"K40jg-Ah7LPE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":425},"outputId":"bc1d1bdf-fa68-416e-e8bd-380d7166b66b","executionInfo":{"status":"ok","timestamp":1577175931319,"user_tz":-60,"elapsed":494,"user":{"displayName":"Kotaro Sonoda","photoUrl":"","userId":"14975548384331586092"}}},"source":["model = models.Sequential()\n","model.add(layers.Conv2D(128,(5,5), activation='relu', input_shape=(28,28,3)))\n","model.add(layers.MaxPooling2D((2,2)))\n","model.add(layers.Conv2D(128,(3,3), activation='relu'))\n","model.add(layers.MaxPooling2D((2,2)))\n","model.add(layers.Conv2D(64,(3,3), activation='relu'))\n","model.add(layers.Flatten())\n","model.add(layers.Dense(64, activation = 'relu' ))\n","model.add(layers.Dense(10,activation='softmax'))\n","\n","model.summary()"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Model: \"sequential_9\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_25 (Conv2D)           (None, 24, 24, 128)       9728      \n","_________________________________________________________________\n","max_pooling2d_17 (MaxPooling (None, 12, 12, 128)       0         \n","_________________________________________________________________\n","conv2d_26 (Conv2D)           (None, 10, 10, 128)       147584    \n","_________________________________________________________________\n","max_pooling2d_18 (MaxPooling (None, 5, 5, 128)         0         \n","_________________________________________________________________\n","conv2d_27 (Conv2D)           (None, 3, 3, 64)          73792     \n","_________________________________________________________________\n","flatten_9 (Flatten)          (None, 576)               0         \n","_________________________________________________________________\n","dense_17 (Dense)             (None, 64)                36928     \n","_________________________________________________________________\n","dense_18 (Dense)             (None, 10)                650       \n","=================================================================\n","Total params: 268,682\n","Trainable params: 268,682\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gOO0oMoh7haL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"90ae5175-f9c6-470c-c076-8b51f3c8b44c","executionInfo":{"status":"ok","timestamp":1577175932372,"user_tz":-60,"elapsed":505,"user":{"displayName":"Kotaro Sonoda","photoUrl":"","userId":"14975548384331586092"}}},"source":["print(\"Number of parameters\")\n","print(\"conv2d (1):\", 5*5*3*128+128) # (filter width) x (filter height) x (input image channel) + (bias)\n","print(\"conv2d (2):\", 3*3*128*128+128) # (filter width) x (filter height) x (input channel size) x (output channel size) + (bias) \n","print(\"conv2d (3):\", 3*3*128*64+64) # (filter width) x (filter height) x (input channel size) x (output channel size) + (bias) \n","print(\"dense (1):\", 576*64+64) # (input channel size) x (output channel size) + (bias = output channel size)\n","print(\"dense (2):\", 64 * 10 +10) # # (input channel size) x (output channel size) + (bias = output channel size)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Number of parameters\n","conv2d (1): 9728\n","conv2d (2): 147584\n","conv2d (3): 73792\n","dense (1): 36928\n","dense (2): 650\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9-4Ed6DpIqL0","colab_type":"text"},"source":["### Dependence of the output shape on the stride and padding"]},{"cell_type":"markdown","metadata":{"id":"ysbbJaVhIhFD","colab_type":"text"},"source":["Let us check how stride and padding affect the output shape. If you do not understand explanations below, check figures 5.5 and 5.6 on page 126,"]},{"cell_type":"markdown","metadata":{"id":"_GP0Cd8vJEUZ","colab_type":"text"},"source":["1. Since the size of the convolution window is (3,3), the output shape (not including a depth axis) is reduced by 2, i.e., (28-2, 28-2, 32) = (26,26,32)."]},{"cell_type":"code","metadata":{"id":"3Ep8kndcBCzN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"outputId":"64be42cf-6fc0-46dd-af7c-70faa943e50f","executionInfo":{"status":"ok","timestamp":1577178227113,"user_tz":-60,"elapsed":727,"user":{"displayName":"Kotaro Sonoda","photoUrl":"","userId":"14975548384331586092"}}},"source":["model = models.Sequential()\n","model.add(layers.Conv2D(32,(3,3), strides=1,padding='valid' ,activation='relu', input_shape=(28,28,1)))\n","model.summary()"],"execution_count":66,"outputs":[{"output_type":"stream","text":["Model: \"sequential_41\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_97 (Conv2D)           (None, 26, 26, 32)        320       \n","=================================================================\n","Total params: 320\n","Trainable params: 320\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CBqsgBRtJzvu","colab_type":"text"},"source":["2. Because strides = 2, the output shape is almost the half of the input shape."]},{"cell_type":"code","metadata":{"id":"tqlclCTcI_Ia","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"outputId":"f6aa28d2-fc70-43a3-bec4-abcfc937fea2","executionInfo":{"status":"ok","timestamp":1577178112734,"user_tz":-60,"elapsed":716,"user":{"displayName":"Kotaro Sonoda","photoUrl":"","userId":"14975548384331586092"}}},"source":["model = models.Sequential()\n","model.add(layers.Conv2D(32,(3,3), strides=2, padding='valid' ,activation='relu', input_shape=(28,28,1)))\n","model.summary()"],"execution_count":64,"outputs":[{"output_type":"stream","text":["Model: \"sequential_39\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_95 (Conv2D)           (None, 13, 13, 32)        320       \n","=================================================================\n","Total params: 320\n","Trainable params: 320\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JAunqpuoKBaU","colab_type":"text"},"source":["3. Because the padding is activated, the output shape is the same as the input shape."]},{"cell_type":"code","metadata":{"id":"lKMxORZMJ-Pq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"outputId":"9881764f-1e4d-427a-8b37-d3e24790c2a6","executionInfo":{"status":"ok","timestamp":1577178367831,"user_tz":-60,"elapsed":443,"user":{"displayName":"Kotaro Sonoda","photoUrl":"","userId":"14975548384331586092"}}},"source":["model = models.Sequential()\n","model.add(layers.Conv2D(32,(3,3), strides=1,padding='same' ,activation='relu', input_shape=(28,28,1)))\n","model.summary()"],"execution_count":67,"outputs":[{"output_type":"stream","text":["Model: \"sequential_42\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_98 (Conv2D)           (None, 28, 28, 32)        320       \n","=================================================================\n","Total params: 320\n","Trainable params: 320\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"U4fSg1o9KleT","colab_type":"text"},"source":["4. Since the size of the convolution window is (5,5), the output shape (not including a depth axis) is reduced by 4, i.e., (28-4, 28-4, 32) = (24,24,32)"]},{"cell_type":"code","metadata":{"id":"wHWkLdhxKjZA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"outputId":"bf6d65df-8a6b-4a91-fbb0-d11475c0a868","executionInfo":{"status":"ok","timestamp":1577178516282,"user_tz":-60,"elapsed":731,"user":{"displayName":"Kotaro Sonoda","photoUrl":"","userId":"14975548384331586092"}}},"source":["model = models.Sequential()\n","model.add(layers.Conv2D(32,(5,5), strides=1,padding='valid' ,activation='relu', input_shape=(28,28,1)))\n","model.summary()"],"execution_count":69,"outputs":[{"output_type":"stream","text":["Model: \"sequential_44\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_100 (Conv2D)          (None, 24, 24, 32)        832       \n","=================================================================\n","Total params: 832\n","Trainable params: 832\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rfKpR-zaAmVQ","colab_type":"text"},"source":["## Application to MNIST data"]},{"cell_type":"markdown","metadata":{"id":"opkRj5EPAvTa","colab_type":"text"},"source":["Let us get and process MNIST data."]},{"cell_type":"code","metadata":{"id":"hhkuHZWUcgCw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"outputId":"eae03d19-35cd-4abe-c186-d5c37826c8f0","executionInfo":{"status":"ok","timestamp":1577175251050,"user_tz":-60,"elapsed":2468,"user":{"displayName":"Kotaro Sonoda","photoUrl":"","userId":"14975548384331586092"}}},"source":["from keras.datasets import mnist\n","from keras.utils import to_categorical\n","\n","# get data\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","\n","# normalization and reshaping\n","train_images=train_images.reshape((60000, 28, 28, 1)) # specify the RGB channel. \n","train_images=train_images.astype('float32')/255 # normalization\n","\n","test_images=test_images.reshape((10000, 28,28, 1)) # change the shape\n","test_images=test_images.astype('float32')/255 # normalization\n","\n","# show sizes of data\n","print(\"train_images shape: {}\".format(train_images.shape))\n","print(\"train_labels shape: {}\".format(train_labels.shape))\n","print(\"test_images shape: {}\".format(test_images.shape))\n","print(\"test_labels shape: {}\".format(test_labels.shape))\n","\n","# one-hot encoding\n","train_labels = to_categorical(train_labels)\n","test_labels = to_categorical(test_labels)\n","print(\"\\nAfter implementing one-hot encoding, the sizes of labels are:\")\n","print(\"train_labels shape: \", train_labels.shape)\n","print(\"test_labels shape: \", test_labels.shape)\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n","11493376/11490434 [==============================] - 1s 0us/step\n","train_images shape: (60000, 28, 28, 1)\n","train_labels shape: (60000,)\n","test_images shape: (10000, 28, 28, 1)\n","test_labels shape: (10000,)\n","\n","After implementing one-hot encoding, the sizes of labels are:\n","train_labels shape:  (60000, 10)\n","test_labels shape:  (10000, 10)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eS2R34CrA2f9","colab_type":"text"},"source":["A model will be defined and trained in the next cell."]},{"cell_type":"code","metadata":{"id":"kAaDmsZVcrJ1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"outputId":"8bae9696-8801-48ec-a513-784ab1a634b2","executionInfo":{"status":"ok","timestamp":1577175324167,"user_tz":-60,"elapsed":21594,"user":{"displayName":"Kotaro Sonoda","photoUrl":"","userId":"14975548384331586092"}}},"source":["model = models.Sequential()\n","model.add(layers.Conv2D(32,(3,3), activation='relu', input_shape=(28,28,1)))\n","model.add(layers.MaxPooling2D((2,2)))\n","model.add(layers.Conv2D(64,(3,3), activation='relu'))\n","model.add(layers.MaxPooling2D((2,2)))\n","model.add(layers.Conv2D(64,(3,3), activation='relu'))\n","model.add(layers.Flatten())\n","model.add(layers.Dense(64, activation = 'relu' ))\n","model.add(layers.Dense(10,activation='softmax'))\n","\n","model.compile(optimizer = 'rmsprop',\n","                      loss = 'categorical_crossentropy',\n","                       metrics=['accuracy'])\n","history = model.fit(train_images, train_labels, epochs = 5, batch_size=64)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","60000/60000 [==============================] - 4s 72us/step - loss: 0.1670 - acc: 0.9467\n","Epoch 2/5\n","60000/60000 [==============================] - 4s 67us/step - loss: 0.0446 - acc: 0.9860\n","Epoch 3/5\n","60000/60000 [==============================] - 4s 67us/step - loss: 0.0313 - acc: 0.9902\n","Epoch 4/5\n","60000/60000 [==============================] - 4s 67us/step - loss: 0.0239 - acc: 0.9927\n","Epoch 5/5\n","60000/60000 [==============================] - 4s 66us/step - loss: 0.0184 - acc: 0.9941\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hOHIEDFZA7H1","colab_type":"text"},"source":["The loss and accuracy for test dataset will be shown."]},{"cell_type":"code","metadata":{"id":"y2m0GAnW94m7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"3c19a4e1-53fa-4090-e57b-2f00475db3bd","executionInfo":{"status":"ok","timestamp":1577175327558,"user_tz":-60,"elapsed":1402,"user":{"displayName":"Kotaro Sonoda","photoUrl":"","userId":"14975548384331586092"}}},"source":["results = model.evaluate(test_images, test_labels)\n","results"],"execution_count":10,"outputs":[{"output_type":"stream","text":["10000/10000 [==============================] - 1s 59us/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.032889669519441486, 0.99]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"wp3bJphR-Z19","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WM_El0c7-eSC","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}